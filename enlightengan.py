# -*- coding: utf-8 -*-
"""enlightenGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a9O3e7IEhLN0jXzDL_rWsIsMhR8PwIgC
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/VITA-Group/EnlightenGAN.git
# %cd EnlightenGAN

!pip install torch torchvision
!pip install dominate

pip install git+https://github.com/arsenyinfo/EnlightenGAN-inference.git

!pip install git+https://github.com/arsenyinfo/EnlightenGAN-inference.git

import zipfile
import os

zip_path = "/content/Bicycle.zip"
extract_path = "/content/Bicycle"

# Unzip if not already extracted
if not os.path.exists(extract_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

print("‚úÖ Dataset extracted to:", extract_path)
print("Sample files:", os.listdir(extract_path)[:10])

import zipfile
import os

zip_path = "/content/photos.zip"
extract_path = "/content/photos"

# Unzip if not already extracted
if not os.path.exists(extract_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

print("‚úÖ Dataset extracted to:", extract_path)
print("Sample files:", os.listdir(extract_path)[:10])

import os

extract_path = "/content/Bicycle"   # change if you extracted somewhere else
print("Sample files:", os.listdir(extract_path)[:10])

from enlighten_inference import EnlightenOnnxModel
import cv2
import os
import matplotlib.pyplot as plt

# Use CPU provider in Colab since GPU may not be available
model_gan = EnlightenOnnxModel(providers=["CPUExecutionProvider"])
print("‚úÖ EnlightenGAN model loaded")

# Replace with a valid image path from your unzip folder
img_path = "/content/Bicycle/2015_00532.jpg"
if not os.path.exists(img_path):
    raise FileNotFoundError(f"No image found at: {img_path}")

# Read and convert to RGB
img = cv2.imread(img_path)
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Run enhancement
enhanced = model_gan.predict(img_rgb)

# Show comparison
plt.figure(figsize=(12,6))
plt.subplot(1,2,1); plt.title("Original"); plt.imshow(img_rgb); plt.axis("off")
plt.subplot(1,2,2); plt.title("Enhanced ‚Äì EnlightenGAN"); plt.imshow(enhanced); plt.axis("off")
plt.show()



# Replace with a valid image path from your unzip folder
img_path = "/content/rat2.jpeg"

if not os.path.exists(img_path):
    raise FileNotFoundError(f"No image found at: {img_path}")

# Read and convert to RGB
img = cv2.imread(img_path)
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Run enhancement
enhanced = model_gan.predict(img_rgb)

# Show comparison
plt.figure(figsize=(12,6))
plt.subplot(1,2,1); plt.title("Original"); plt.imshow(img_rgb); plt.axis("off")
plt.subplot(1,2,2); plt.title("Enhanced ‚Äì EnlightenGAN"); plt.imshow(enhanced); plt.axis("off")
plt.show()

import os
import zipfile
import cv2
import matplotlib.pyplot as plt
import numpy as np
from google.colab import files

# --- STEP 1: Upload ZIP file ---
print("üìÇ Please upload your ZIP file containing images...")
uploaded = files.upload()

# Get the uploaded filename
zip_path = list(uploaded.keys())[0]
print(f"‚úÖ Uploaded: {zip_path}")

# --- STEP 2: Extract ZIP contents ---
extract_dir = "/content/unzipped_images"
if not os.path.exists(extract_dir):
    os.makedirs(extract_dir)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print(f"‚úÖ Extracted all images to: {extract_dir}")

# --- STEP 3: Prepare save directory for enhanced results ---
save_dir = "/content/enhanced_images"
os.makedirs(save_dir, exist_ok=True)

# --- STEP 4: Collect all image paths ---
valid_exts = ('.jpg', '.jpeg', '.png', '.bmp')
image_files = [os.path.join(extract_dir, f) for f in os.listdir(extract_dir) if f.lower().endswith(valid_exts)]

if not image_files:
    raise FileNotFoundError("‚ùå No valid image files found inside the ZIP!")

print(f"üîç Found {len(image_files)} image(s). Enhancing now...")

# --- STEP 5: Enhance each image using your GAN model ---
for img_path in image_files:
    try:
        # Read and convert to RGB
        img = cv2.imread(img_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Run enhancement (replace this with your GAN model‚Äôs predict)
        enhanced = model_gan.predict(img_rgb)

        # Convert and save enhanced image
        save_path = os.path.join(save_dir, "enhanced_" + os.path.basename(img_path))
        enhanced_bgr = cv2.cvtColor(np.array(enhanced, dtype=np.uint8), cv2.COLOR_RGB2BGR)
        cv2.imwrite(save_path, enhanced_bgr)
        print(f"üíæ Saved: {save_path}")

    except Exception as e:
        print(f"‚ùå Failed to enhance {img_path}: {e}")

print(f"\nüéâ Enhancement completed! All enhanced images are saved in: {save_dir}")

# --- Optional: Display a few enhanced results for preview ---
sample_files = image_files[:3]  # show first 3 images only
for img_path in sample_files:
    orig = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)
    enh_path = os.path.join(save_dir, "enhanced_" + os.path.basename(img_path))
    enh = cv2.cvtColor(cv2.imread(enh_path), cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(12,6))
    plt.subplot(1,2,1); plt.title("Original"); plt.imshow(orig); plt.axis("off")
    plt.subplot(1,2,2); plt.title("Enhanced ‚Äì EnlightenGAN"); plt.imshow(enh); plt.axis("off")
    plt.suptitle(os.path.basename(img_path))
    plt.show()

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import onnxruntime as ort
import random
from pathlib import Path
import gc

!wget https://huggingface.co/spaces/akhaliq/EnlightenGAN/resolve/main/enlightengan.onnx -O /content/enlightengan.onnx

import requests

url = "https://huggingface.co/spaces/akhaliq/EnlightenGAN/resolve/main/enlightengan.onnx"
output_path = "/content/enlightengan.onnx"

response = requests.get(url)
with open(output_path, "wb") as f:
    f.write(response.content)

print("Download completed!")

def enhance_image_with_gan(session, img_rgb):
    """Enhance one image using EnlightenGAN ONNX."""
    # Preprocess: normalize and add batch
    inp = img_rgb.astype(np.float32) / 255.0
    inp = np.transpose(inp, (2, 0, 1))  # HWC ‚Üí CHW
    inp = np.expand_dims(inp, axis=0)   # add batch

    # Run inference
    out = session.run(None, {session.get_inputs()[0].name: inp})[0]

    # Postprocess back to [0,255]
    out_img = np.squeeze(out).transpose(1, 2, 0)
    out_img = np.clip(out_img * 255.0, 0, 255).astype(np.uint8)
    return out_img

# ----------------------
# Process 100 Images
# ----------------------
data_dir = Path("/content/Bicycle")   # dataset folder
output_dir = Path("/content/enhanced_enlightengan")
output_dir.mkdir(parents=True, exist_ok=True)

# Pick 100 random images
all_images = [f for f in data_dir.glob("*.jpg")] + [f for f in data_dir.glob("*.JPG")]
selected = random.sample(all_images, 100)

print(f"Total selected: {len(selected)}")

for idx, fp in enumerate(selected, start=1):
    try:
        img = cv2.imread(str(fp))
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img_rgb = cv2.resize(img_rgb, (400, 400))  # resize before model

        # Enhance
        enhanced = enhance_image_with_gan(session, img_rgb)

        # Save
        out_path = output_dir / f"enh_{idx:03d}.png"
        cv2.imwrite(str(out_path), cv2.cvtColor(enhanced, cv2.COLOR_RGB2BGR))

        print(f"[{idx}/100] Saved: {out_path.name}")

        # Free memory
        del img, img_rgb, enhanced
        gc.collect()

    except Exception as e:
        print(f"Error processing {fp.name}: {e}")

print("‚úÖ Enhancement completed for 100 images!")

# ------------------------------
# Step 0: Install dependencies if needed
# ------------------------------
!pip install onnx onnxruntime opencv-python matplotlib --quiet

# ------------------------------
# Step 1: Upload EnlightenGAN ONNX manually
# ------------------------------
from google.colab import files
uploaded = files.upload()  # select enlightengan.onnx from your computer

import os
model_path = list(uploaded.keys())[0]  # gets the uploaded file name
print(f"‚úÖ Model uploaded: {model_path}, size: {os.path.getsize(model_path)} bytes")

# ------------------------------
# Step 2: Validate ONNX model
# ------------------------------
import onnx
onnx_model = onnx.load(model_path)
onnx.checker.check_model(onnx_model)
print("‚úÖ ONNX model is valid!")

# ------------------------------
# Step 3: Load model with ONNXRuntime
# ------------------------------
import onnxruntime as ort
session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])
print("‚úÖ ONNXRuntime session ready")

# ------------------------------
# Step 4: Image enhancement function
# ------------------------------
import cv2
import numpy as np
import random
import gc
from pathlib import Path

def enhance_image_with_gan(session, img_rgb):
    inp = img_rgb.astype(np.float32) / 255.0
    inp = np.transpose(inp, (2, 0, 1))  # HWC -> CHW
    inp = np.expand_dims(inp, axis=0)
    out = session.run(None, {session.get_inputs()[0].name: inp})[0]
    out_img = np.squeeze(out).transpose(1, 2, 0)
    out_img = np.clip(out_img * 255.0, 0, 255).astype(np.uint8)
    return out_img

# ------------------------------
# ------------------------------
# Step 5: Process 100 images (save with original names)
# ------------------------------
data_dir = Path("/content/Bicycle.zip")   # folder with your images
output_dir = Path("/content/enhanced_enlightengan")
output_dir.mkdir(parents=True, exist_ok=True)

all_images = [f for f in data_dir.glob("*.jpg")] + [f for f in data_dir.glob("*.JPG")]
if len(all_images) < 100:
    selected = all_images
    print(f"Only {len(all_images)} images available, will process all.")
else:
    selected = random.sample(all_images, 100)
print(f"Total selected: {len(selected)}")

for idx, fp in enumerate(selected, start=1):
    try:
        img = cv2.imread(str(fp))
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img_rgb = cv2.resize(img_rgb, (400, 400))

        enhanced = enhance_image_with_gan(session, img_rgb)

        # ‚úÖ Save with same stem name (original filename but .png)
        out_path = output_dir / f"{fp.stem}.png"
        cv2.imwrite(str(out_path), cv2.cvtColor(enhanced, cv2.COLOR_RGB2BGR))
        print(f"[{idx}/{len(selected)}] Saved: {out_path.name}")

        del img, img_rgb, enhanced
        gc.collect()
    except Exception as e:
        print(f"Error processing {fp.name}: {e}")

print("‚úÖ Enhancement completed with original filenames!")

import matplotlib.pyplot as plt
import cv2
from pathlib import Path
import random

# Directories
input_dir = Path("/content/photos.zip")
output_dir = Path("/content/enhanced_enlightengan")

# Get only images that have enhanced versions
enhanced_files = {f.stem for f in output_dir.glob("*.png")}
all_images = [f for f in input_dir.glob("*.jpg")] + [f for f in input_dir.glob("*.JPG")]
matched_images = [f for f in all_images if f.stem in enhanced_files]

# Pick 5 random images that have enhanced versions
sample_images = random.sample(matched_images, min(5, len(matched_images)))

for img_path in sample_images:
    orig = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)
    enhanced_path = output_dir / f"{img_path.stem}.png"
    enhanced = cv2.cvtColor(cv2.imread(str(enhanced_path)), cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(10,5))
    plt.subplot(1,2,1)
    plt.imshow(orig)
    plt.title("Original")
    plt.axis("off")

    plt.subplot(1,2,2)
    plt.imshow(enhanced)
    plt.title("Enhanced")
    plt.axis("off")
    plt.show()

import matplotlib.pyplot as plt
import cv2
from pathlib import Path
import random

# Directories
input_dir = Path("/content/Bicycle.zip")
output_dir = Path("/content/enhanced_enlightengan")

# Get only images that have enhanced versions
enhanced_files = {f.stem for f in output_dir.glob("*.png")}
all_images = [f for f in input_dir.glob("*.jpg")] + [f for f in input_dir.glob("*.JPG")]
matched_images = [f for f in all_images if f.stem in enhanced_files]

# Pick 3 random matched images
sample_images = random.sample(matched_images, min(3, len(matched_images)))

for img_path in sample_images:
    # Original
    orig = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)

    # Enhanced
    enhanced_path = output_dir / f"{img_path.stem}.png"
    enhanced = cv2.cvtColor(cv2.imread(str(enhanced_path)), cv2.COLOR_BGR2RGB)

    # Plot side by side
    plt.figure(figsize=(10,5))
    plt.subplot(1,2,1)
    plt.imshow(orig)
    plt.title("Original")
    plt.axis("off")

    plt.subplot(1,2,2)
    plt.imshow(enhanced)
    plt.title("Enhanced")
    plt.axis("off")

    plt.show()

from pathlib import Path
import cv2
import numpy as np
from skimage.metrics import peak_signal_noise_ratio

# Directories
input_dir = Path("/content/Bicycle")
output_dir = Path("/content/enhanced_enlightengan")

enh_images = sorted(output_dir.glob("enh_*.png"))
orig_files = sorted(list(input_dir.glob("*.jpg")) + list(input_dir.glob("*.JPG")))

def calculate_psnr(orig_path, enh_path):
    orig = cv2.imread(str(orig_path))
    enh  = cv2.imread(str(enh_path))

    if orig is None or enh is None:
        print(f"‚ùå Could not load {orig_path} or {enh_path}")
        return None

    # Resize enhanced to match original
    enh = cv2.resize(enh, (orig.shape[1], orig.shape[0]))

    psnr_val = float(peak_signal_noise_ratio(orig, enh, data_range=255))
    return psnr_val

# Loop through 100 images
results = []
for idx, enh_path in enumerate(enh_images[:100], start=1):
    try:
        orig_idx = int(enh_path.stem.split("_")[1]) - 1
        if orig_idx >= len(orig_files):
            print(f"‚ö†Ô∏è No matching original for {enh_path.name}")
            continue

        orig_path = orig_files[orig_idx]
        psnr = calculate_psnr(orig_path, enh_path)
        if psnr is None:
            continue

        print(f"‚úÖ Pair {idx}: {orig_path.name} ‚Üî {enh_path.name} | PSNR: {psnr:.2f} dB")
        results.append(psnr)
    except Exception as e:
        print(f"‚ö†Ô∏è Skipping {enh_path.name}: {e}")

# Summary
if results:
    print("\nüìä Average PSNR over processed images:")
    print(f"{np.mean(results):.2f} dB")

from pathlib import Path
import cv2
import numpy as np
from skimage.metrics import peak_signal_noise_ratio

# -------------------------------
# Directories
# -------------------------------
input_dir = Path("/content/Bicycle")  # Original images
output_dir = Path("/content/enhanced_enlightengan")  # Optional: store enhanced images

enh_images = sorted(output_dir.glob("enh_*.png"))
orig_files = sorted(list(input_dir.glob("*.jpg")) + list(input_dir.glob("*.JPG")))

# -------------------------------
# Enhancement functions
# -------------------------------
def gamma_correction(img, gamma=1.3):
    img = img.astype(np.float32) / 255.0
    img = np.power(img, 1/gamma)
    img = np.clip(img*255, 0, 255).astype(np.uint8)
    return img

def apply_clahe(img):
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    l = clahe.apply(l)
    lab = cv2.merge((l,a,b))
    img_clahe = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
    return img_clahe

def denoise(img):
    return cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)

def enhance_image(img):
    img = gamma_correction(img, gamma=1.3)
    img = apply_clahe(img)
    img = denoise(img)
    return img

# -------------------------------
# PSNR calculation
# -------------------------------
def calculate_psnr(orig_path, enh_path):
    orig = cv2.imread(str(orig_path))
    enh  = cv2.imread(str(enh_path))

    if orig is None or enh is None:
        print(f"‚ùå Could not load {orig_path} or {enh_path}")
        return None

    # Convert to RGB
    orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)
    enh  = cv2.cvtColor(enh, cv2.COLOR_BGR2RGB)

    # Resize enhanced to match original
    enh = cv2.resize(enh, (orig.shape[1], orig.shape[0]))

    # Apply enhancement
    enh = enhance_image(enh)

    psnr_val = float(peak_signal_noise_ratio(orig, enh, data_range=255))
    return psnr_val

# -------------------------------
# Process 100 images
# -------------------------------
results = []
for idx, enh_path in enumerate(enh_images[:100], start=1):
    try:
        orig_idx = int(enh_path.stem.split("_")[1]) - 1
        if orig_idx >= len(orig_files):
            print(f"‚ö†Ô∏è No matching original for {enh_path.name}")
            continue

        orig_path = orig_files[orig_idx]
        psnr = calculate_psnr(orig_path, enh_path)
        if psnr is None:
            continue

        print(f"‚úÖ Pair {idx}: {orig_path.name} ‚Üî {enh_path.name} | PSNR: {psnr:.2f} dB")
        results.append(psnr)
    except Exception as e:
        print(f"‚ö†Ô∏è Skipping {enh_path.name}: {e}")

# -------------------------------
# Summary
# -------------------------------
if results:
    print("\nüìä Average PSNR over processed images:")
    print(f"{np.mean(results):.2f} dB")

pip install brisque

import os

image_path = '/content/enhanced_enlightengan/enh_001.png'
print(os.path.exists(image_path))  # Should print True

import cv2
img = cv2.imread(image_path, cv2.IMREAD_COLOR)
if img is None:
    print(f"‚ùå Failed to load {image_path}")
else:
    print("‚úÖ Image loaded successfully")

from pathlib import Path
from brisque import BRISQUE
import cv2

output_dir = Path("/content/enhanced_enlightengan")
brisque = BRISQUE()

for img_path in sorted(output_dir.glob("enh_*.png")):
    img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)
    if img is None:
        print(f"‚ùå Could not load {img_path.name}, skipping")
        continue

    # Convert grayscale to BGR if needed
    if len(img.shape) == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    score = brisque.score(img)
    print(f"{img_path.name} ‚Üí BRISQUE: {score:.2f}")

from pathlib import Path
import cv2
from brisque import BRISQUE
import numpy as np

# -------------------------------
# Directories
# -------------------------------
output_dir = Path("/content/enhanced_enlightengan")  # Enhanced images folder
enh_images = sorted(output_dir.glob("enh_*.png"))    # Grab all PNG images

# Initialize BRISQUE model
brisque_model = BRISQUE()

# -------------------------------
# Loop through images
# -------------------------------
results = []

for idx, img_path in enumerate(enh_images[:100], start=1):  # Limit to first 100
    img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)

    if img is None:
        print(f"‚ùå Could not load {img_path.name}, skipping")
        continue

    # Convert grayscale to BGR if needed
    if len(img.shape) == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    try:
        score = brisque_model.score(img)
        print(f"‚úÖ {idx}: {img_path.name} ‚Üí BRISQUE: {score:.2f}")
        results.append(score)
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to compute BRISQUE for {img_path.name}: {e}")

# -------------------------------
# Summary
# -------------------------------
if results:
    print("\nüìä Average BRISQUE score over processed images:")
    print(f"{np.mean(results):.2f}")
else:
    print("‚ö†Ô∏è No BRISQUE scores computed.")

from pathlib import Path
import cv2
from brisque import BRISQUE
import numpy as np

# -------------------------------
# Directories
# -------------------------------
output_dir = Path("/content/enhanced_enlightengan")  # Enhanced images folder
enh_images = sorted(output_dir.glob("enh_*.png"))    # Grab all PNG images

# Initialize BRISQUE model
brisque_model = BRISQUE()

# -------------------------------
# Enhancement functions
# -------------------------------
def gamma_correction(img, gamma=1.15):
    img = img.astype(np.float32) / 255.0
    img = np.power(img, 1/gamma)
    img = np.clip(img*255, 0, 255).astype(np.uint8)
    return img

def apply_clahe(img, clipLimit=1.5):
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=(8,8))
    l = clahe.apply(l)
    lab = cv2.merge((l,a,b))
    img_clahe = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
    return img_clahe

def denoise(img):
    return cv2.fastNlMeansDenoisingColored(img, None, 15, 15, 7, 21)

def enhance_image(img):
    img = gamma_correction(img, gamma=1.15)
    img = apply_clahe(img, clipLimit=1.5)
    img = denoise(img)
    return img

# -------------------------------
# Compute BRISQUE
# -------------------------------
results = []

for idx, img_path in enumerate(enh_images[:100], start=1):
    img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)

    if img is None:
        print(f"‚ùå Could not load {img_path.name}, skipping")
        continue

    # Convert grayscale to BGR if needed
    if len(img.shape) == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    # Apply optimized enhancement
    enhanced_img = enhance_image(img)

    try:
        score = brisque_model.score(enhanced_img)
        print(f"‚úÖ {idx}: {img_path.name} ‚Üí BRISQUE: {score:.2f}")
        results.append(score)
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to compute BRISQUE for {img_path.name}: {e}")

# -------------------------------
# Summary
# -------------------------------
if results:
    print("\nüìä Average BRISQUE score over processed images:")
    print(f"{np.mean(results):.2f}")
else:
    print("‚ö†Ô∏è No BRISQUE scores computed.")

from pathlib import Path
import cv2
from brisque import BRISQUE
import numpy as np

# -------------------------------
# Directories
# -------------------------------
input_dir = Path("/content/enhanced_enlightengan")  # Original enhanced images
output_dir = Path("/content/enhanced_optimized")   # Folder to save newly enhanced images
output_dir.mkdir(parents=True, exist_ok=True)

enh_images = sorted(input_dir.glob("enh_*.png"))

# Initialize BRISQUE model
brisque_model = BRISQUE()

# -------------------------------
# Enhancement functions
# -------------------------------
def gamma_correction(img, gamma=1.15):
    img = img.astype(np.float32) / 255.0
    img = np.power(img, 1/gamma)
    img = np.clip(img*255, 0, 255).astype(np.uint8)
    return img

def apply_clahe(img, clipLimit=1.5):
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=(8,8))
    l = clahe.apply(l)
    lab = cv2.merge((l,a,b))
    img_clahe = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
    return img_clahe

def denoise(img):
    return cv2.fastNlMeansDenoisingColored(img, None, 15, 15, 7, 21)

def enhance_image(img):
    img = gamma_correction(img, gamma=1.15)
    img = apply_clahe(img, clipLimit=1.5)
    img = denoise(img)
    return img

# -------------------------------
# Process images
# -------------------------------
results = []

for idx, img_path in enumerate(enh_images[:100], start=1):
    img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)

    if img is None:
        print(f"‚ùå Could not load {img_path.name}, skipping")
        continue

    # Convert grayscale to BGR if needed
    if len(img.shape) == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)

    # Apply optimized enhancement
    enhanced_img = enhance_image(img)

    # Save the enhanced image
    save_path = output_dir / img_path.name
    cv2.imwrite(str(save_path), cv2.cvtColor(enhanced_img, cv2.COLOR_RGB2BGR))

    # Compute BRISQUE
    try:
        score = brisque_model.score(enhanced_img)
        print(f"‚úÖ {idx}: {img_path.name} ‚Üí BRISQUE: {score:.2f}")
        results.append(score)
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to compute BRISQUE for {img_path.name}: {e}")

# -------------------------------
# Summary
# -------------------------------
if results:
    print("\nüìä Average BRISQUE score over processed images:")
    print(f"{np.mean(results):.2f}")
else:
    print("‚ö†Ô∏è No BRISQUE scores computed.")

